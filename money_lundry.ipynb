{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98125b57",
   "metadata": {},
   "source": [
    "# 洗錢\n",
    "- 筆記: https://www.notion.so/jayschsu/c6a6219dd004469bbbfbecfb6d9883f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "4cea619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import namedtuple\n",
    "\n",
    "SCORE_TUPLE = namedtuple('SCORE_TUPLE', 'feature, preprocess, sampling, model, iter, precision')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ff097",
   "metadata": {},
   "source": [
    "### Data\n",
    "- dp_df\n",
    "    - DEBIT是進錢(+) & CREDIT是出錢(-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "ceb13de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cust_data(cust_id):\n",
    "    display(custinfo_df[custinfo_df['cust_id']==cust_id].style.set_caption('custinfo_df'))\n",
    "    display(ccba_df[ccba_df['cust_id']==cust_id].style.set_caption('ccba_df'))\n",
    "    display(cdtx_df[cdtx_df['cust_id']==cust_id].style.set_caption('cdtx_df'))\n",
    "    display(dp_df[dp_df['cust_id']==cust_id].style.set_caption('dp_df'))\n",
    "    display(remit_df[remit_df['cust_id']==cust_id].style.set_caption('remit_df'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7e83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccba_df = pd.read_csv('data/dataset1/public_train_x_ccba_full_hashed.csv')\n",
    "cdtx_df = pd.read_csv('data/dataset1/public_train_x_cdtx0001_full_hashed.csv')\n",
    "custinfo_df = pd.read_csv('data/dataset1/public_train_x_custinfo_full_hashed.csv')\n",
    "dp_df = pd.read_csv('data/dataset1/public_train_x_dp_full_hashed.csv')\n",
    "remit_df = pd.read_csv('data/dataset1/public_train_x_remit1_full_hashed.csv')\n",
    "tr_alertX_df = pd.read_csv('data/dataset1/train_x_alert_date.csv')\n",
    "tr_sarY_df = pd.read_csv('data/dataset1/train_y_answer.csv')\n",
    "public_alertX_df = pd.read_csv('data/dataset1/public_x_alert_date.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a57e9b",
   "metadata": {},
   "source": [
    "**Preprocess**\n",
    "- 將alert_date, sar_flag merge到custinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277ee842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid_data_qty: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayhsu/Library/Python/3.8/lib/python/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#mapping alert_date & sar flag\n",
    "alertDate_dict = tr_alertX_df.set_index('alert_key').to_dict()['date']\n",
    "sarFlag_dict = tr_sarY_df.set_index('alert_key').to_dict()['sar_flag']\n",
    "public_alertX_df['sar_flag']=2\n",
    "alertDatePublc_dict = public_alertX_df.set_index('alert_key').to_dict()['date']\n",
    "sarFlagPublic_dict = public_alertX_df.set_index('alert_key').to_dict()['sar_flag']\n",
    "custinfo_df['alert_date'] = custinfo_df['alert_key'].map(lambda x: alertDate_dict[x] if x in alertDate_dict else alertDatePublc_dict[x] )\n",
    "custinfo_df['sar_flag'] = custinfo_df['alert_key'].map(lambda x: sarFlag_dict[x] if x in sarFlag_dict else sarFlagPublic_dict[x])\n",
    "custinfo_df['sar_flag_nunique'] = custinfo_df.groupby(['cust_id','alert_date'])['sar_flag'].transform('nunique')\n",
    "invalid_data_qty = sum(custinfo_df['sar_flag_nunique']>1)\n",
    "print(f'invalid_data_qty: {invalid_data_qty}')\n",
    "custinfo_valid = custinfo_df[custinfo_df['sar_flag_nunique']==1]\n",
    "custinfo_valid.drop_duplicates(['cust_id','alert_date','sar_flag'], inplace=True)\n",
    "custinfo_valid = custinfo_valid.set_index(['cust_id','alert_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131626ba",
   "metadata": {},
   "source": [
    "## Feturing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c2303",
   "metadata": {},
   "source": [
    "**1. by Date**\n",
    "1. 把各種資料表轉換為以date為單位的特徵\n",
    "- ccba: 信用卡相關資料, 以月為單位的資料, 缺少public dataset區間,不需處理\n",
    "    \n",
    "- cdtx: 消費細項\n",
    "    - 每日消費金額\n",
    "    - 每日消費次數\n",
    "    - 每日台幣消費金額\n",
    "    - 每日台幣消費次數   \n",
    "    - 每日外幣消費金額\n",
    "    - 每日外幣消費次數\n",
    "    - 每日國內消費金額\n",
    "    - 每日國內消費次數    \n",
    "    - 每日國外消費金額\n",
    "    - 每日國外消費次數\n",
    "- dp: 借貸: 金額需要乘上匯率\n",
    "    - 借貸金額\n",
    "    - 借貸次數\n",
    "    - CR金額\n",
    "    - CR次數\n",
    "    - DB金額\n",
    "    - DB次數\n",
    "    - 臨櫃現金交易金額\n",
    "    - 臨櫃現金交易次數\n",
    "    - 非臨櫃現金交易金額\n",
    "    - 非臨櫃現金交易次數 \n",
    "    - 跨行交易金額\n",
    "    - 跨行交易次數\n",
    "    - 非跨行交易金額\n",
    "    - 非跨行交易次數\n",
    "    - 實體ATM交易金額\n",
    "    - 實體ATM交易次數\n",
    "    - 非實體ATM交易金額\n",
    "    - 非實體ATM交易次數  \n",
    "    - 分行數量\n",
    "- remit\n",
    "    - 外匯金額\n",
    "    - 外匯次數    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "3bae15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdtx\n",
    "cdtxDate_ = cdtx_df.groupby(['cust_id','date']).agg(cdtxAmt_ADate=('amt', sum), cdtxCnt_ADate=('date', 'count'))\n",
    "cdtxDate_ntd = cdtx_df[cdtx_df['cur_type']==47].groupby(['cust_id','date']).agg(cdtxAmtNTD_ADate=('amt', sum), cdtxCntNTD_ADate=('date', 'count'))\n",
    "cdtxDate_fc = cdtx_df[cdtx_df['cur_type']!=47].groupby(['cust_id','date']).agg(cdtxAmtFC_ADate=('amt', sum), cdtxCntFC_ADate=('date', 'count'))\n",
    "cdtxDate_tw = cdtx_df[cdtx_df['country']==130].groupby(['cust_id','date']).agg(cdtxAmtTW_ADate=('amt', sum), cdtxCntTW_ADate=('date', 'count'))\n",
    "cdtxDate_f = cdtx_df[cdtx_df['country']!=130].groupby(['cust_id','date']).agg(cdtxAmtF_ADate=('amt', sum), cdtxCntF_ADate=('date', 'count'))\n",
    "cdtxDate_df = pd.concat([cdtxDate_, cdtxDate_ntd, cdtxDate_fc, cdtxDate_tw, cdtxDate_f], axis=1)\n",
    "\n",
    "#dp\n",
    "dp_df['amt'] = dp_df['tx_amt']*dp_df['exchg_rate']\n",
    "dpDate_ = dp_df.groupby(['cust_id','tx_date']).agg(dpAmt_ADate=('tx_amt', sum), dpCnt_ADate=('tx_date', 'count'))\n",
    "dpDate_CR = dp_df[dp_df['debit_credit']=='CR'].groupby(['cust_id','tx_date']).agg(dpAmtCR_ADate=('tx_amt', sum), dpCntCR_ADate=('tx_date', 'count'))\n",
    "dpDate_DB = dp_df[dp_df['debit_credit']=='CB'].groupby(['cust_id','tx_date']).agg(dpAmtDB_ADate=('tx_amt', sum), dpCntDB_ADate=('tx_date', 'count'))\n",
    "dpDate_CC = dp_df[(dp_df['tx_type']==1)&(dp_df['info_asset_code']==12)].groupby(['cust_id','tx_date']).agg(dpAmtCC_ADate=('tx_amt', sum), dpCntCC_ADate=('tx_date', 'count'))\n",
    "dpDate_NCC = dp_df[~((dp_df['tx_type']==1)&(dp_df['info_asset_code']==12))].groupby(['cust_id','tx_date']).agg(dpAmtNCC_ADate=('tx_amt', sum), dpCntNCC_ADate=('tx_date', 'count'))\n",
    "dpDate_CBank = dp_df[dp_df['cross_bank']==1].groupby(['cust_id','tx_date']).agg(dpAmtCBank_ADate=('tx_amt', sum), dpCntCBank_ADate=('tx_date', 'count'))\n",
    "dpDate_InBank = dp_df[dp_df['cross_bank']==0].groupby(['cust_id','tx_date']).agg(dpAmtInBank_ADate=('tx_amt', sum), dpCntInBank_ADate=('tx_date', 'count'))\n",
    "dpDate_ATM = dp_df[dp_df['ATM']==1].groupby(['cust_id','tx_date']).agg(dpAmtATM_ADate=('tx_amt', sum), dpCntATM_ADate=('tx_date', 'count'))\n",
    "dpDate_NATM = dp_df[dp_df['ATM']==0].groupby(['cust_id','tx_date']).agg(dpAmtNATM_ADate=('tx_amt', sum), dpCntNATM_ADate=('tx_date', 'count'))\n",
    "dpDate_branchNunique = dp_df.groupby(['cust_id','tx_date']).agg(dpBranchNunique_ADate=('txbranch', 'nunique'))\n",
    "dpDate_df = pd.concat([dpDate_, dpDate_CR, dpDate_DB, dpDate_CC, dpDate_NCC, dpDate_CBank, dpDate_InBank, dpDate_ATM, dpDate_NATM, dpDate_branchNunique], axis=1)\n",
    "\n",
    "#remit\n",
    "remitDate_df = remit_df.groupby(['cust_id','trans_date']).agg(remitAmt_ADate=('trade_amount_usd', sum), remitCnt_ADate=('trans_no', 'count'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72c97b",
   "metadata": {},
   "source": [
    "**2. Accumulate recent K days**   \n",
    "- accumulate feature: 整合前K天的feature\n",
    "- Process: 每一個customer要分別做以下的feature engineering\n",
    "    - 1. 組合cust_id * dates\n",
    "    - 2. merge with date feature\n",
    "    - 3. calculate accum feature\n",
    "    - 4. merge date and accum features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ea7eb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accum_feature(cust_data, cust_id, date_colName, rolling_window):\n",
    "    dates = list(range(cust_data.index.min(), cust_data.index.max()+1))\n",
    "    all_custDate = pd.DataFrame(list(product([cust_id], dates)), columns=['cust_id', date_colName]).set_index(['cust_id', date_colName])\n",
    "    cust_fullDate = pd.merge(cust_data, all_custDate, how='outer', left_index=True, right_index=True)\n",
    "    cust_fullDate.sort_index(ascending=True, inplace=True)\n",
    "    cust_fullDate.fillna(0, inplace=True)\n",
    "    cust_recentAccum = cust_fullDate.rolling(window = rolling_window, min_periods=1).sum().shift()\n",
    "    new_cols = []\n",
    "    for c in cust_recentAccum.columns:\n",
    "        new_cols.append(c+'_Accum')\n",
    "    cust_recentAccum.columns=new_cols\n",
    "    feature = pd.merge(cust_data, cust_recentAccum, how='left', left_index=True, right_index=True)\n",
    "    return feature\n",
    "\n",
    "def get_accum_feature_V2(cust_data, cust_id, date_colName, rolling_window):\n",
    "    dates = list(range(cust_data.index.min(), cust_data.index.max()+1))\n",
    "    all_custDate = pd.DataFrame(list(product([cust_id], dates)), columns=['cust_id', date_colName]).set_index(['cust_id', date_colName])\n",
    "    cust_fullDate = pd.merge(cust_data, all_custDate, how='outer', left_index=True, right_index=True)\n",
    "    cust_fullDate.sort_index(ascending=True, inplace=True)\n",
    "    cust_fullDate.fillna(0, inplace=True)\n",
    "    \n",
    "    cust_recentAccum = cust_fullDate.rolling(window=rolling_window, min_periods=1).mean().shift()\n",
    "    cust_recentAccum2W = cust_fullDate.rolling(window=rolling_window*2, min_periods=1).mean().shift()\n",
    "    cust_recentAccumDiff = cust_recentAccum*2 - cust_recentAccum2W\n",
    "    cust_fullDateDiff = cust_fullDate - cust_recentAccum\n",
    "    \n",
    "    new_cols = []\n",
    "    for c in cust_recentAccum.columns:\n",
    "        new_cols.append(c.replace('_ADate', '_Accum'))\n",
    "    cust_recentAccum.columns=new_cols\n",
    "    \n",
    "    new_cols = []\n",
    "    for c in cust_recentAccumDiff.columns:\n",
    "        new_cols.append(c.replace('_ADate', '_AccumDiff'))\n",
    "    cust_recentAccumDiff.columns=new_cols\n",
    "    \n",
    "    new_cols = []\n",
    "    for c in cust_fullDateDiff.columns:\n",
    "        new_cols.append(c.replace('_ADate', '_ADateDiff'))\n",
    "    cust_fullDateDiff.columns=new_cols        \n",
    "    \n",
    "    feature = pd.merge(cust_data, cust_fullDateDiff, how='left', left_index=True, right_index=True)\n",
    "    feature = pd.merge(feature, cust_recentAccum, how='left', left_index=True, right_index=True)\n",
    "    feature = pd.merge(feature, cust_recentAccumDiff, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    return feature\n",
    "\n",
    "def accum_featuring_parallel(dateFeature, date_colName='date', rolling_window=5):\n",
    "    idx_custid, _ = zip(*dateFeature.index)\n",
    "    idx_custid = np.unique(idx_custid)\n",
    "    accu_feature_list = Parallel(n_jobs=4)(delayed(get_accum_feature_V2)(dateFeature.loc[(cust_id)], cust_id, date_colName, rolling_window) for cust_id in idx_custid) \n",
    "    accu_feature = pd.concat(accu_feature_list)\n",
    "    return accu_feature\n",
    "\n",
    "def get_recallN_Precision(y_predProb, y_true):\n",
    "    y_pred_df = pd.DataFrame(list(zip(y_predProb, y_true)), columns=['predProb','trueLabel'])\n",
    "    y_pred_df.sort_values(by='predProb', ascending=False, inplace=True)\n",
    "    y_pred_df['idx']=list(range(len(y_pred_df)))\n",
    "    idx = y_pred_df[y_pred_df['trueLabel']==1]['idx'].iloc[-2]\n",
    "    precision_score = sum(y_true)/idx\n",
    "    return precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0e76c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.9 s, sys: 2.63 s, total: 36.5 s\n",
      "Wall time: 47.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cdtx_feature = accum_featuring_parallel(cdtxDate_df, 'date', rolling_window=3)\n",
    "dp_feature = accum_featuring_parallel(dpDate_df, 'tx_date', rolling_window=3)\n",
    "remit_feature = accum_featuring_parallel(remitDate_df, 'trans_date', rolling_window=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2e266",
   "metadata": {},
   "source": [
    "**3. cust profile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "558af539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ccba\n",
    "ccbaProfile1 = ccba_df.replace(0, np.nan).groupby('cust_id').agg(\n",
    "                               ccbalupayAmt_Year=('lupay', np.mean),\\\n",
    "                               ccbausgamAmt_Year=('usgam', np.mean),\\\n",
    "                               ccbacycamAax_Year=('cycam', np.max),\\\n",
    "                               ccbaclamtAmt_Year=('clamt', np.mean),\\\n",
    "                               ccbacsamtAmt_Year=('csamt', np.mean),\\\n",
    "                               ccbainamtAmt_Year=('inamt', np.mean),\\\n",
    "                               ccbacucsmAmt_Year=('cucsm', np.mean),\\\n",
    "                               ccbacucahAmt_Year=('cucah', np.mean),\\\n",
    "                              )\n",
    "ccbaProfile2 = ccba_df.groupby('cust_id').agg(ccbalupayCnt_Year=('lupay', np.count_nonzero),\\\n",
    "                               ccbausgamCnt_Year=('usgam', np.count_nonzero),\\\n",
    "                               ccbaclamtCnt_Year=('clamt', np.count_nonzero),\\\n",
    "                               ccbacsamtCnt_Year=('csamt', np.count_nonzero),\\\n",
    "                               ccbainamtCnt_Year=('inamt', np.count_nonzero),\\\n",
    "                               ccbacucsmCnt_Year=('cucsm', np.count_nonzero),\\\n",
    "                               ccbacucahCnt_Year=('cucah', np.count_nonzero),\\\n",
    "                               ccbabyymmCnt_Year=('byymm', np.count_nonzero),\\\n",
    "                              )\n",
    "ccbaProfile_df = pd.concat([ccbaProfile1, ccbaProfile2], axis=1)\n",
    "\n",
    "\n",
    "new_cols = []\n",
    "for c in custinfo_valid.columns:\n",
    "    if c in ['alert_key', 'sar_flag', 'sar_flag_nunique']:\n",
    "        new_cols.append(c)\n",
    "    else:\n",
    "        new_cols.append(c+'_Profile')\n",
    "custinfo_valid.columns=new_cols\n",
    "\n",
    "custProfile_df = pd.merge(custinfo_valid.reset_index(level=1), ccbaProfile_df, left_index=True, right_index=True, how='left')\n",
    "custProfile_df.set_index('alert_date', append=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17acf1f9",
   "metadata": {},
   "source": [
    "**3. Integrate dataset**\n",
    "- moneyLundry dataset (sar_flag==1, in alert_date)\n",
    "- falseAlarm dataset (sar_flag==0, in alert_date)\n",
    "- public dataset (sar_flag==2, in alert_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "b8635dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([custProfile_df, cdtx_feature, dp_feature, remit_feature], axis=1)\n",
    "data_df = data_df[data_df['alert_key'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "664422ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sar_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>23451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sar_flag\n",
       "0.0     23451\n",
       "2.0      1770\n",
       "1.0       233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_Tr: (23684, 35)\n",
      "dataset_TsPub: (1770, 35)\n"
     ]
    }
   ],
   "source": [
    "labelY = 'sar_flag'\n",
    "feature_all = [x for x in data_df.columns if x not in ['alert_key', 'sar_flag', 'sar_flag_nunique']]\n",
    "feature_Profile = [x for x in data_df.columns if x.split('_')[-1]=='Profile']\n",
    "feature_ADate = [x for x in data_df.columns if x.split('_')[-1]=='ADate']\n",
    "feature_ADateDiff = [x for x in data_df.columns if x.split('_')[-1]=='ADateDiff']\n",
    "feature_Accum = [x for x in data_df.columns if x.split('_')[-1]=='Accum']\n",
    "feature_AccumDiff = [x for x in data_df.columns if x.split('_')[-1]=='AccumDiff']\n",
    "feature_Year = [x for x in data_df.columns if x.split('_')[-1]=='Year']\n",
    "assert len(feature_all)==len(feature_Profile+feature_ADate+feature_ADateDiff+feature_Accum+feature_AccumDiff+feature_Year)\n",
    "\n",
    "#--- \n",
    "\n",
    "\n",
    "display(data_df[labelY].value_counts().to_frame())\n",
    "dataset_Tr = data_df[data_df['sar_flag']!=2]\n",
    "dataset_TsPub = data_df[data_df['sar_flag']==2]\n",
    "\n",
    "print('dataset_Tr:', dataset_Tr.shape)\n",
    "print('dataset_TsPub:', dataset_TsPub.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b480a9",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "629ee605",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipePreMinMax = Pipeline([('sc', MinMaxScaler()), ('pca', PCA(n_components=0.9))])\n",
    "pipePreStd = Pipeline([('sc', StandardScaler()), ('pca', PCA(n_components=0.9))])\n",
    "pipePreMMStd = Pipeline([('sc1', MinMaxScaler()), ('sc2', StandardScaler()), ('pca', PCA(n_components=0.9))])\n",
    "pipe_list = zip([pipePreMinMax, pipePreStd, pipePreMMStd], ['MinMaxScaler','StandardScaler','MinMaxScaler+StandardScaler'])\n",
    "pipe_list = list(pipe_list)\n",
    "\n",
    "pipeSpSmote = imbPipeline([('sp', SMOTE(n_jobs=-1))])\n",
    "pipeSpBSmote = imbPipeline([('sp', BorderlineSMOTE(n_jobs=-1))])\n",
    "pipeSpTom = imbPipeline([('sp', TomekLinks(n_jobs=-1))])\n",
    "pipeSpSmoteTom = imbPipeline([('sp1', BorderlineSMOTE(n_jobs=-1)), ('sp2', TomekLinks(n_jobs=-1))])\n",
    "sp_list = zip([pipeSpSmote, pipeSpBSmote, pipeSpTom, pipeSpSmoteTom], ['SMOTE', 'BorderlineSMOTE', 'TomekLinks', 'BorderlineSMOTE+TomekLinks'])\n",
    "sp_list = list(sp_list)\n",
    "\n",
    "modelLR = LogisticRegression(max_iter=300)\n",
    "modelXGBC = XGBClassifier(use_label_encoder=False)\n",
    "modelMLPC = MLPClassifier(max_iter=1000)\n",
    "model_list = zip([modelLR, modelXGBC, modelMLPC], ['LogisticRegression', 'XGBClassifier', 'MLPClassifier'])\n",
    "model_list = list(model_list)\n",
    "\n",
    "featureD = feature_ADate\n",
    "featurePD = feature_Profile+feature_ADate\n",
    "featurePDA = feature_Profile+feature_ADate+feature_Accum\n",
    "featurePDAY = feature_Profile+feature_ADate+feature_Accum+feature_Year\n",
    "featureD_Diff = feature_ADateDiff\n",
    "featurePD_Diff = feature_Profile+feature_ADateDiff\n",
    "featurePDA_Diff = feature_Profile+feature_ADateDiff+feature_AccumDiff\n",
    "featurePDAY_Diff = feature_Profile+feature_ADateDiff+feature_AccumDiff+feature_Year\n",
    "featureD_Composite = feature_ADate+feature_ADateDiff\n",
    "featurePD_Composite = feature_Profile+feature_ADate+feature_ADateDiff\n",
    "featurePDA_Composite = feature_Profile+feature_ADate+feature_Accum+feature_ADateDiff+feature_AccumDiff\n",
    "featurePDAY_Composite = feature_Profile+feature_ADate+feature_Accum+feature_ADateDiff+feature_AccumDiff+feature_Year\n",
    "feature_list = [featureD, featurePD, featurePDA, featurePDAY, featureD_Diff, featurePD_Diff, featurePDA_Diff, featurePDAY_Diff, featureD_Composite, featurePD_Composite, featurePDA_Composite, featurePDAY_Composite]\n",
    "feature_list = zip(feature_list,['D', 'PD', 'PDA', 'PDAY', 'D_Diff', 'PD_Diff','PDA_Diff','PDAY_Diff','D_Composite','PD_Composite', 'PDA_Composite', 'PDAY_Composite'])\n",
    "feature_list = list(feature_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52159b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:05:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:07:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:08:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:08:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:09:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:11:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:12:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:12:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:13:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:13:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:15:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:17:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:21:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:23:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:23:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:24:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:24:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:25:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:26:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:27:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:27:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:28:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:29:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:30:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:30:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:31:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:32:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:33:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:33:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:37:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:41:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:42:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:42:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:42:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:43:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:45:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:45:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:45:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:47:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:48:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:52:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:53:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:53:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for featureX, featureName in feature_list:\n",
    "    #KFold, Cross-validate\n",
    "    X = dataset_Tr[featureX].fillna(0).copy()\n",
    "    Y = dataset_Tr[labelY]\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=23)\n",
    "    skf.get_n_splits(X,Y)\n",
    "\n",
    "    score_list = []\n",
    "    for i, (tr_idx, val_idx) in enumerate(skf.split(X, Y)):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = Y.iloc[tr_idx], Y.iloc[val_idx]\n",
    "\n",
    "        for pipePre, pipePreName in pipe_list:\n",
    "            for pipeSp, pipeSpName in sp_list:\n",
    "                predProb_list = []\n",
    "                for model, modelName in model_list:\n",
    "                    #preprocess\n",
    "                    pipePre.fit(X_tr)\n",
    "                    x_tr_ = pipePre.transform(X_tr.copy())\n",
    "                    x_val_ = pipePre.transform(X_val.copy())\n",
    "                    #over sampling\n",
    "                    x_re, y_re = pipeSp.fit_resample(x_tr_, y_tr)\n",
    "                    #tr&pred\n",
    "                    model = model.fit(x_re, y_re)        \n",
    "                    y_predProb = model.predict_proba(x_val_)\n",
    "                    #scole\n",
    "                    y_predProb = [x[1] for x in y_predProb]\n",
    "                    precisionScore = get_recallN_Precision(y_predProb, y_val)\n",
    "                    score_list.append(SCORE_TUPLE(featureName, pipePreName, pipeSpName, modelName, i, precisionScore))\n",
    "                    predProb_list.append(y_predProb)\n",
    "\n",
    "                precisionScore = get_recallN_Precision(np.mean(predProb_list, axis=0), y_val)\n",
    "                score_list.append(SCORE_TUPLE(featureName, pipePreName, pipeSpName, 'ensemble', i, precisionScore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3828ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(score_list)\n",
    "display(score_df.groupby('model')['precision'].mean().to_frame())\n",
    "display(score_df.groupby(['model','iter'])['precision'].max().to_frame())\n",
    "display(score_df.groupby(['iter','model'])['precision'].max().to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780fba33",
   "metadata": {},
   "source": [
    "- profile + date: 0.014338\n",
    "- date + ccba: 0.012114\n",
    "- date + accumulate: 0.013388\n",
    "- date + accumulate + ccbaProfile: 0.012036\n",
    "- date + dateDiff+ accumulate+ accumulateDiff + ccbaProfile: 0.012238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd5508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf4f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
